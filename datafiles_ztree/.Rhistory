matrix(rexp(200), 10)
size <- 20             #length of random number vectors
set.seed(1)
x <- runif(size)          # generate samples from uniform distribution (0.0, 1.0)
y <-runif(size)
df <-data.frame(x,y)
df
xmeans (df, ik=4)
plot (df)
size <- 200             #length of random number vectors
set.seed(1)
x <- runif(size)          # generate samples from uniform distribution (0.0, 1.0)
y <-runif(size)
df <-data.frame(x,y)
xmeans (df, ik=4)
plot (df)
y = xmeans (df, ik=4)
y$cluster
plot (df)
setwd("~/Desktop/API_VNM_DS2_en_csv_v2/")
data = read.csv("API_VNM_DS2_en_csv_v2.csv")
x = 1684
t = 1.05
x*t^10
x*t^50
x*t^100
x*t^50
x*t^60
x*t^70
x*t^65
x*t^65
x=1:12000
y1 = log(x/1000 + 1)
plot (y1~x)
y1 = log(x/1000 + 1)/4
plot (y1~x)
x = seq(1:12000,10)
?seq
x = seq(1,12000,10)
x
y1 = log(x/1000 + 1)/4
plot (y1~x)
x = seq(1,12000,50)
y1 = log(x/1000 + 1)/4
plot (y1~x)
plot (y1~x, type = "l")
x = seq(1,12000,50)
x1 = seq (1,2000,20)
f1 = log (x1/1000 + 1)/4
plot (f1 ~ x)
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/3
plot (f1 ~ x1)
plot (f1 ~ x1)/1.234
f1 = log (x1/1000 + 1)/1.35
plot (f1 ~ x1)/1.234
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/1.46
plot (f1 ~ x1)
f1 = log (x1/1000 + 1)/1.623
plot (f1 ~ x1)
length(f1)
?runif
f1 = c(f1, rep(0.65, length(x) - length(f1)))
length(f1)
plot (f1 ~ x)
plot (f1 ~ x, type = l)
plot (f1 ~ x, type = "l")
plot (f1 ~ x, type = "l", col = "red")
f2 = f1 + runif (length(f1), max=0.1,min=-0.1)
plot (f2 ~ x, type = "l", col = "red")
f2 = f1 + rnorm (length(f1), max=0.1,min=-0.1)
?rnorm
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red")
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.623 + 0.18
plot (f1~x1)
plot (f1~x1, ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.913 + 0.18
plot (f1~x1, ylim=c(0,1))
f1 = c(f1, rep(0.65, length(x) - length(f1)))
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f1 = log (x1/1000 + 1)/1.983 + 0.18
f1 = c(f1, rep(0.65, length(x) - length(f1)))
f2 = f1 + runif (length(f1), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/1.983 + 0.18, rep(0.65, length(x) - length(f1))) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983 + 0.18, rep(0.65, 10000)) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983, 0.18, rep(0.65, 10000)) + runif (length(f1), max=0.02,min=-0.05)
f2 = c(log (x1/1000 + 1)/1.983 + 0.181, rep(0.65, 10000)) + runif (length(x), max=0.02,min=-0.05)
length(x1)
f2 = c(log (x1/1000 + 1)/1.983 + 0.181, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.181, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.05)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.02,min=-0.075)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.08,min=-0.175)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
f2 = c(log (x1/1000 + 1)/2.014 + 0.161, rep(0.65, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.1)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1))
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid())
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.68, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
plot (f3~x,add =TRUE, col = "blue")
plot (f3~x,add =TRUE, col = "blue", type = "l")
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.72, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
f3 = c(log (x1/1000 + 1)/1.874 + 0.1736, rep(0.72, length(x)-length(x1))) + runif (length(x), max=0.05,min=-0.03)
plot (f3~x,add =TRUE, col = "blue", type = "l")
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
lines(f3, add=TRUE)
lines(f3~x, add=TRUE)
plot (f2 ~ x, type = "l", col = "red", ylim=c(0,1), panel.first = grid(), xlab="Training steps", ylab="Accuracy")
lines(f3~x, add=TRUE)
install.packages("h2o")
df = read.csv("https://goo.gl/uWbihf", sep = ";")
str(df)
df = read.csv("https://goo.gl/uWbihf", sep = ";", header = FALSE)
str(df)
library (h2o)
h2o.shutdown ()
?h2o.gbm
library(h2o)
?h2o.gbm
?h2o.grid
library(h2o)
devtools::install_github("rstudio/tensorflow")
library (tensorflow)
library(reticulate)
use_condaenv("tensorflow")
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
library(tensorflow)
# Create 100 phony x, y data points, y = x * 0.1 + 0.3
x_data <- runif(100, min=0, max=1)
y_data <- x_data * 0.1 + 0.3
# Try to find values for W and b that compute y_data = W * x_data + b
# (We know that W should be 0.1 and b 0.3, but TensorFlow will
# figure that out for us.)
W <- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0))
b <- tf$Variable(tf$zeros(shape(1L)))
y <- W * x_data + b
# Minimize the mean squared errors.
loss <- tf$reduce_mean((y - y_data) ^ 2)
optimizer <- tf$train$GradientDescentOptimizer(0.5)
train <- optimizer$minimize(loss)
# Launch the graph and initialize the variables.
sess = tf$Session()
sess$run(tf$global_variables_initializer())
# Fit the line (Learns best fit is W: 0.1, b: 0.3)
for (step in 1:201) {
sess$run(train)
if (step %% 20 == 0)
cat(step, "-", sess$run(W), sess$run(b), "\n")
}
tf.__version__
tf$VERSION
tf$Print(train)
library(oce)
install.packages("oce")
library(oce)
## Example 1. color scheme for points on xy plot
x <- seq(0, 1, length.out = 40)
y <- sin(2 * pi * x)
par(mar = c(3, 3, 1, 1))
mar <- par("mar")  # prevent margin creep by drawPalette()
## First, default breaks
c <- Colormap(y)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
plot(x, y, bg = c$zcol, pch = 21, cex = 1)
grid()
## Example 1. color scheme for points on xy plot
x <- seq(0, 1, length.out = 40)
y <- sin(2 * pi * x)
par(mar = c(3, 3, 1, 1))
mar <- par("mar")  # prevent margin creep by drawPalette()
## First, default breaks
c <- colormap(y)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
plot(x, y, bg = c$zcol, pch = 21, cex = 1)
grid()
par(mar = mar)
## Second, 100 breaks, yielding a smoother palette
c <- Colormap(y, breaks = 100)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
plot(x, y, bg = c$zcol, pch = 21, cex = 1)
grid()
par(mar = mar)
## Second, 100 breaks, yielding a smoother palette
c <- colormap(y, breaks = 100)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
plot(x, y, bg = c$zcol, pch = 21, cex = 1)
grid()
c
plot(x, y, bg = c$zcol, pch = 21, cex = 1)
grid()
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
y
y = 1:10
c <- colormap(y)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
dev.off()
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
c
?colormap
y <- c(370,
380,
400,
418,
425,
430,
433,
438,
455,
465,
470,
493,
522)
c <- colormap (y)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
dev.off
dev.off()
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
dev.off()
c <- colormap (y, breaks = 10)
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
c <- colormap (y, breaks = 1)
dev.off()
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
c <- colormap(y)
dev.off()
drawPalette(c$zlim, col = c$col, breaks = c$breaks)
max(y)
c
cm <- colormap(name = "gmt_globe")
deep <- cm$x0 < -4000
cm$col0[deep] <- "black"
cm$col1[deep] <- "black"
cm <- Colormap(x0 = cm$x0, x1 = cm$x1, col0 = cm$col0, col1 = cm$col1)
imagep(topoWorld, breaks = cm$breaks, col = cm$col)
cm <- colormap(name = "gmt_globe")
deep <- cm$x0 < -4000
cm$col0[deep] <- "black"
cm$col1[deep] <- "black"
cm <- colormap(x0 = cm$x0, x1 = cm$x1, col0 = cm$col0, col1 = cm$col1)
imagep(topoWorld, breaks = cm$breaks, col = cm$col)
Rozaro_revenue <- 0.23
Erumac_revenue <- 0.18
len_revenue <- 0.3
total_pop <- 500 * 1e6
total_conn <- 400 * 1e6
total_conn * Rozaro_revenue
two_services <- c(0.45,0.7,0.8)
voice <- c(60,40,5)
data <- c(40,35,2)
voice * (1 - two_services) + data * (1 - two_services)
sum (THVL | Ban nhạc quyền năng - Tập 7)
sum (voice * (1 - two_services) + data * (1 - two_services)
)
sum (voice  + data * (1 - two_services))
sum (voice * (1 - two_services) + data)
devtools::install_github("rstudio/keras")
library (keras)
install_tensorflow(gpu = TRUE)
pf (q = 2.4836, df1 = 4, df2 = 25)
1 - pf (q = 2.4836, df1 = 4, df2 = 25)
1 - pf(1,28,55.07)
1 - pf (55.07, 1, 28)
1 - pf (5.18, 2, 27)
1 - pf (.64, 2, 27)
1 - pf (2.21, 2, 27)
?TukeyHSD()
setwd("~/workspace/detect_malicious_time_series")
df11k <- read.csv("data11k.csv")
str(df11k)
df1 <- read.csv("data_20170711/blocks_info_40-1.json.csv")
str(df1)
df4 <- read.csv("data_20170711/blocks_info_40-4.json.csv")
df10 <- read.csv("data_20170711/blocks_info_40-10.json.csv")
source("time.R")
source("time.R")
S1 <- BFED(train_series = df11k$diff, test_series = df1$diff, subsequence_len = 10)
plot (S1)
plot(df1$diff)
min (which(S1 == min (S1)))
min (which (df1$malicious == 1))
plot (S1)
S1_10 <- S1
S1_20 <- BFED(train_series = df11k$diff, test_series = df1$diff, subsequence_len = 20)
setwd("~/workspace/dTrust")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(R.matlab, h2o, hydroGOF, scales)
filename = "epinions_rating_with_timestamp.mat"
rating = readMat(filename)
rating = rating$rating
rating = as.data.frame(rating)
colnames(rating) = c("User","Product","Category","Rating","Helpfulnesss","Timestamp")
str(rating)
trust_file = "epinion_trust_with_timestamp.mat"
rating_file = "epinions_rating_with_timestamp.mat"
trust_data = readMat(trust_file)
trust_data = as.data.frame(trust_data$trust)
colnames (trust_data) = c("Trustor","Trustee","Timestamp")
rating = readMat(rating_file)
rating = rating$rating
rating = as.data.frame(rating)
colnames(rating) = c("User","Product","Category","Rating","Helpfulnesss","Timestamp")
rating$User = rating$User + max(rating$Product) + 1000
trust_data$Trustor = trust_data$Trustor + max(rating$Product) + 1000
rating$User = as.factor(rating$User)
# rating$V2 = as.factor(rating$V2)
rating$Category = as.factor(rating$Category)
if (time_point == FALSE) {
rating$Timestamp = sapply(rating$Timestamp, FUN=convert_time_stamp)
}
# set category for friend
friend_category = max(as.integer(rating$Category)) + 1
trust_data$Rating = 5
trust_data$Category = friend_category
# reorder the columns
trust = trust_data[,c(1,2,5,4,3)]
# remove helpfulness
rating$Helpfulnesss = NULL
# unify col names
colnames(rating) = c("src","dst","category","rating","timestamp")
colnames(trust) = c("src","dst","category","rating","timestamp")
# temporary switch category to integer
rating$category = as.integer(rating$category)
# add Type col to recognize after merge
rating$Type = "Rating"
trust$Type = "Trust"
# create a big dataframe
total_df = rbind (rating, trust)
str(total_df)
write.csv(x = total_df, file = "epinions2_full.csv", sep = "\t", col.names = TRUE, row.names = FALSE)
write.csv(x = total_df, file = "epinions2_full.csv", sep = "\t", col.names = TRUE, row.names = FALSE, quote = FALSE)
install.packages("h2o")
library(raster)
library(ggplot2)
vietnam <- getData("GADM",country="Vietnam",level=2)
china <- getData("GADM",country="China",level=0)
laos <- getData("GADM",country="Laos",level=0)
cambodia <- getData("GADM",country="Cambodia",level=0)
thailand <- getData("GADM",country="Thailand",level=0)
ggplot(vietnam,aes(x=long,y=lat,group=group))+
geom_polygon(aes(fill=id),color="grey30")+
geom_polygon(data=china,fill="grey60",color="grey80")+
geom_polygon(data=laos,fill="grey60",color="grey80")+
geom_polygon(data=cambodia,fill="grey60",color="grey80")+
geom_polygon(data=thailand,fill="grey60",color="grey80")+
coord_map(xlim=c(-1,1)+bbox(vietnam)["x",],ylim=c(-1,1)+bbox(vietnam)["y",])+
scale_fill_discrete(guide="none")+
theme_bw()+theme(panel.grid=element_blank())
install.packages("fpp")
setwd("~/workspace/trust_influence_analysis/datafiles_ztree")
#Read data files into R
source ("ProcessData.R")
zTT <- readMultiXLS ("./all_data")
SBJs <- processMultiSBJ ("./all_data")
# Create my sending proportional
zTT[2]$subjects$my_send_proportional <- ifelse(zTT[2]$subjects$Type == 0, zTT[2]$subjects$Contribution/10, ifelse(zTT[2]$subjects$PartnerDecision > 0, zTT[2]$subjects$Contribution/3/zTT[2]$subjects$PartnerDecision, -1))
# add epsilon value to avoid the case 0/0
# EPSILON = 0.001
# zTT[2]$subjects$my_send_proportional <- ifelse(zTT[2]$subjects$Type == 0, zTT[2]$subjects$Contribution/10,  zTT[2]$subjects$Contribution/3/ (zTT[2]$subjects$PartnerDecision + EPSILON))
zTT[2]$subjects$CurrGameProfit <- ifelse(zTT[2]$subjects$Type == 0, zTT[2]$subjects$PartnerDecision - zTT[2]$subjects$Contribution, zTT[2]$subjects$PartnerDecision*3 - zTT[2]$subjects$Contribution)
# set some constants
# Numbers of user of a group
num_users = 6
# Number of rounds each user play to each other
average_rounds = 5
# Number of games for each group
num_games = 4
# Number of rounds for each game (should be 25)
num_rounds_per_game = (num_users - 1) * average_rounds
# Number of rounds for each experiment (should be 100, because we have 4 games)
num_rounds_per_exp = num_rounds_per_game * num_games
# Number of experiments (it is 5 at the time of writing,
# but can be increased if we organize more experiments)
num_exp = nrow (zTT[1]$globals) / num_rounds_per_exp
Type_names = c("SENDER", "RECEIVER")
SIMPLE_GAME_ORDERS =      c(3,2,4,1,2)
ID_GAME_ORDERS =          c(1,4,1,2,3)
SCORE_GAME_ORDERS =       c(2,1,3,4,4)
COMBINE_GAME_ORDERS =     c(4,3,2,3,1)
GAME_NAMES <- c("Simple GAME", "ID GAME", "Score GAME", "Combine GAME")
col_list <- c("red","green","blue","black","orange","violet")
# first, create empty data frames to hold all the particular games
simple_games <- zTT[2]$subjects[0,]
id_games <- zTT[2]$subjects[0,]
score_games <- zTT[2]$subjects[0,]
combine_games <- zTT[2]$subjects[0,]
# create dataframe for each game
for (exp_id in 1:num_exp) {
first_round_of_exp_globals = (exp_id - 1) * num_rounds_per_exp + 1
last_round_of_exp_globals = exp_id * num_rounds_per_exp
globals_of_exp = zTT[1]$globals[first_round_of_exp_globals:last_round_of_exp_globals,]
first_round_of_exp_subjects = (exp_id - 1) * num_rounds_per_exp * num_users + 1
last_round_of_exp_subjects = exp_id * num_rounds_per_exp * num_users
subjects_of_exp = zTT[2]$subjects[first_round_of_exp_subjects:last_round_of_exp_subjects,]
SIMPLE_GAME_ORDER = globals_of_exp[1,]$SIMPLE_GAME
ID_GAME_ORDER = globals_of_exp[1,]$ID_GAME
SCORE_GAME_ORDER = globals_of_exp[1,]$SCORE_GAME
COMBINE_GAME_ORDER = globals_of_exp[1,]$COMBINE_GAME
simple_games <- rbind(simple_games, subjects_of_exp[((SIMPLE_GAME_ORDER - 1) *
num_rounds_per_game * num_users + 1):
(SIMPLE_GAME_ORDER * num_rounds_per_game * num_users),])
id_games <- rbind(id_games, subjects_of_exp[((ID_GAME_ORDER - 1) *
num_rounds_per_game * num_users + 1):
(ID_GAME_ORDER * num_rounds_per_game * num_users),])
score_games <- rbind(score_games, subjects_of_exp[((SCORE_GAME_ORDER - 1) *
num_rounds_per_game * num_users + 1):
(SCORE_GAME_ORDER * num_rounds_per_game * num_users),])
combine_games <- rbind(combine_games, subjects_of_exp[((COMBINE_GAME_ORDER - 1) *
num_rounds_per_game * num_users + 1):
(COMBINE_GAME_ORDER * num_rounds_per_game * num_users),])
}
CBDT_predict <- function (cur_df, p_recall = 0.75, p_store = 0.5, round_number = 5, type = 0,
show_trust = 0,    # is trust score available to users
show_id = 0,        # is ID available to users
trust_delta = 0.1,   # allow range for remembering trust score
send_delta = 1     # allow range for remembering behavior
) {
print (paste("Analyze: ", Type_names[type+1], "for game:", GAME_NAMES[k]))
# print ("For  rounds 4 and 5")
print (paste("Round", round_number))
cur_df$id <- as.factor (cur_df$id)
cur_df5 <- cur_df [cur_df$round_number_with_partner == round_number,]
lm1 <- lm (RelSend ~ my_trust_value, data = cur_df5)
# print ("Regeression with my trust value")
# print (summary (lm1))
# CBDT for prediction
# p_recall = 0.75  # probability to recall an experience
# p_store = 0.5   # probability to store an experience to memory
cbdt_predicts <- c()  # vector contains predicting values of CBDT
# should have 75 elements in the end in Sender case
for (i in 1:nrow(cur_df5)) {
cur_row <- cur_df5[i,]
cur_id <- cur_row$id[1]
cur_period <- cur_row$period[1]
if (cur_row$RelSend[1] >= 0) {
# scan history to find the best memory
best_payoff <- 0
best_payoff_index <- 0
for (j in 1:nrow(cur_df)) {
# print (paste ("Processing row",j))
if (cur_id == cur_df[j,]$id) {
if (cur_period > cur_df[j,]$period) {
if (show_id == 0 | (show_id == 1 & cur_row$partner_id[1] == cur_df[j,]$partner_id)) {
if (show_trust == 0 | (show_trust == 1 & abs(cur_row$trust_value[1] - cur_df[j,]$trust_value) < trust_delta)) {
r <- runif (1, min = 0, max = 1)
if (r <= p_recall) {
# recall this experience cur_df[j,]
if (type == 0) {
cur_payoff <- cur_df$AbsPartnerSend[j] - cur_df$AbsSend[j]
if (cur_payoff > best_payoff) {
best_payoff <- cur_payoff
best_payoff_index <- j
}
} else if (type == 1) {
if (abs(cur_df5$AbsPartnerSend[i] - cur_df$AbsPartnerSend[j]) < send_delta) {
for (j1 in (j+1):nrow(cur_df)) {
if (cur_df$id[j1] == cur_id) {
if (show_id == 0 | (show_id == 1 & cur_row$partner_id[1] == cur_df[j1,]$partner_id)) {
if (show_trust == 0 | (show_trust == 1 & abs(cur_row$trust_value[1] - cur_df[j1,]$trust_value) < trust_delta)) {
cur_payoff <- cur_df[j+1,]$AbsPartnerSend
if (cur_payoff > best_payoff) {
best_payoff <- cur_payoff
best_payoff_index <- j
}
}
}
}
}
}
}
}
}
}
}
}
}
# predict based on the best memory
if (best_payoff_index == 0) {
pred <- 0.5
cbdt_predicts <- c(cbdt_predicts, pred)
} else {
pred <- cur_df[best_payoff_index,]$RelSend
cbdt_predicts <- c(cbdt_predicts, pred)
}
}
}
print ("CBDT prediction")
# print (cur_df5$RelSend)
# print (predict(lm1, newdata = cur_df5))
# print (cbdt_predicts)
print (paste("R-squared CBDT:", cor(cur_df5$RelSend, cbdt_predicts)^2))
print (paste("R-squared trust-based:", cor(cur_df5$RelSend, cur_df5$my_trust_value)^2))
print (paste("RMSE CBDT:", caret::RMSE(pred = cbdt_predicts, obs = cur_df5$RelSend)))
print (paste("RMSE trust:", caret::RMSE(pred = cur_df5$my_trust_value, obs = cur_df5$RelSend)))
# plot (x=1:nrow(cur_df5), y=cur_df5$RelSend, type = "o", col = col_list[1], lty = 1, xlim = c(0,nrow(cur_df5)+45), ylim = c(0,1), xlab = "Trial", ylab = "Send proportion", main = paste(GAME_NAMES[k]))
# lines(cur_df5$my_trust_value, type = "o", col = col_list[2], lty = 2)
# lines (cbdt_predicts, type = "o", col = col_list[3], lty = 3)
# legend(y=1,x=nrow(cur_df5)+1, col=col_list[1:3], lty=1:3, c("Actual Behavior", "Trust-based prediction", "Case-based prediction"))
# return four values
c(cor(cur_df5$RelSend, cbdt_predicts)^2, cor(cur_df5$RelSend, cur_df5$my_trust_value)^2, caret::RMSE(pred = cbdt_predicts, obs = cur_df5$RelSend), caret::RMSE(pred = cur_df5$my_trust_value, obs = cur_df5$RelSend))
}
